# -*- coding: utf-8 -*-
"""movie-recommender-system.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z1p_tctccd_2uoUgiP7I0hToQ7ryW1LY

Data - https://www.kaggle.com/tmdb/tmdb-movie-metadata
"""

# Commented out IPython magic to ensure Python compatibility.
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import ast
from sklearn.feature_extraction.text import CountVectorizer
import nltk
from nltk.stem.porter import PorterStemmer
from sklearn.metrics.pairwise import cosine_similarity
import pickle
# %matplotlib inline

movies = pd.read_csv('tmdb_5000_movies.csv')
credits = pd.read_csv('tmdb_5000_credits.csv')
moviesss = pd.read_csv('tmdb_5000_movies.csv')

# Combine both dataset with title based

movies = movies.merge(credits, on='title')


#movies.isnull().sum()

# Checking duplicate rows

#movies.duplicated().sum()

movies = movies[['movie_id','title','overview','genres','keywords','cast','crew']]

# Checking Null value

#movies.isnull().sum()

# Deleting the row since it is only 3 null value

movies.dropna(inplace=True)



# genres column

#movies.iloc[0].genres

def convert(obj):
    L = []
    for i in ast.literal_eval(obj):
        L.append(i['name'])
    return L

movies['genres'] = movies['genres'].apply(convert)

# keywords column

#movies.iloc[0].keywords

movies['keywords'] = movies['keywords'].apply(convert)


# Cast column

#movies['cast'][0]

# Taking top 3 name from cast

def convert3(obj):
    L = []
    counter = 0
    for i in ast.literal_eval(obj):
        if counter != 3:
            L.append(i['name'])
            counter+=1
        else:
            break
    return L

movies['cast'] = movies['cast'].apply(convert3)


# crew column

#movies['crew'][0]

# Taking only director from crew only

def fetch_director(obj):
    L = []
    for i in ast.literal_eval(obj):
        if i['job']=='Director':
            L.append(i['name'])
            break
    return L

movies['crew'] = movies['crew'].apply(fetch_director)


# Checking Overview column

#movies['overview'][0]

# Splitting overview

movies['overview'] = movies['overview'].apply(lambda x:x.split())

# Changing
# Sam Worthington --> SamWorthington
# Science Fiction --> ScienceFiction
# culture clash --> cultureclash
# because it will treat Sam Worthington and Sam Waltz as a same

movies['genres']=movies['genres'].apply(lambda x:[i.replace(" ","") for i in x])
movies['keywords']=movies['keywords'].apply(lambda x:[i.replace(" ","") for i in x])
movies['cast']=movies['cast'].apply(lambda x:[i.replace(" ","") for i in x])
movies['crew']=movies['crew'].apply(lambda x:[i.replace(" ","") for i in x])


# Creating tags columns by adding all overview, genres, keywords, cast, crew

movies['tags'] = movies['overview']+movies['genres']+movies['keywords']+movies['cast']+movies['crew']


# Creating new dataframe

new_df = movies[['movie_id','title','tags']]


# Removing commas from tags columns

new_df['tags'] = new_df['tags'].apply(lambda x:" ".join(x))



# Lower case

new_df['tags'] = new_df['tags'].apply(lambda x:x.lower())



# transform a given text into a vector on the basis of the frequency (count) of each word that occurs in the entire text.

cv = CountVectorizer(max_features=5000, stop_words='english')

vectors = cv.fit_transform(new_df['tags']).toarray()


feat_dict=cv.vocabulary_.keys()

# using stemming for same value

ps = PorterStemmer()

def stem(text):
    y=[]
    for i in text.split():
        y.append(ps.stem(i))

    return " ".join(y)

new_df['tags'] = new_df['tags'].apply(stem)

# transform a given text into a vector on the basis of the frequency (count) of each word that occurs in the entire text.
# Doing again after removing stemmer words

cv = CountVectorizer(max_features=5000, stop_words='english')

vectors = cv.fit_transform(new_df['tags']).toarray()

#cv.get_feature_names()


# Using cosine similarity
# It is measured by the cosine of the angle between two vectors and determines whether two vectors are pointing in roughly the same direction.
# It is often used to measure document similarity in text analysis.

similarity = cosine_similarity(vectors)

#sorted(list(enumerate(similarity[1])),reverse=True,key=lambda x:x[1])[1:6]

def recommend(movie):
    movie_index = new_df[new_df['title'] == movie].index[0]
    distances = similarity[movie_index]
    movies_list = sorted(list(enumerate(distances)),reverse=True,key=lambda x:x[1])[1:6]
    ans = []
    for i in movies_list:
        ans.append(new_df.iloc[i[0]].title)
    return ans

s = st.text_input("Enter a movie name")
if(st.button('Submit')):
    try:
        ress = recommend(s)
        for x in ress:
            st.success(x)
    except:
        st.error("No such movie found")  
    

pickle.dump(new_df.to_dict(),open('movie_dict.pkl','wb'))

pickle.dump(similarity,open('similarity.pkl','wb'))

